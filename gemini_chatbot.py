"""
Gemini AI Chatbot Integration
Intelligent chatbot for safety and compliance data analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import json
import re
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Note: In production, you would use the actual Google Gemini API
# For this demo, we'll create a comprehensive mock implementation

class GeminiChatbot:
    """Intelligent chatbot for safety and compliance data analysis"""
    
    def __init__(self, unified_data, kpi_data):
        self.unified_data = unified_data
        self.kpi_data = kpi_data
        self.conversation_history = []
        
        # Initialize knowledge base
        self.knowledge_base = self._build_knowledge_base()
        
        # Common queries and responses
        self.query_patterns = {
            'total_incidents': ['ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«', 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«', 'total incidents'],
            'open_cases': ['Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©', 'Ø§Ù„Ù…ÙØªÙˆØ­', 'open cases'],
            'closed_cases': ['Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©', 'Ø§Ù„Ù…ØºÙ„Ù‚', 'closed cases'],
            'department_performance': ['Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹', 'Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª', 'department performance'],
            'risk_assessment': ['ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±', 'Ø§Ù„Ù…Ø®Ø§Ø·Ø±', 'risk assessment'],
            'compliance_rate': ['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„', 'Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„', 'compliance rate'],
            'trends': ['Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª', 'Ø§Ù„ØªØ·ÙˆØ±', 'trends', 'trend'],
            'statistics': ['Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª', 'statistics', 'stats']
        }
    
    def _build_knowledge_base(self):
        """Build knowledge base from unified data"""
        knowledge = {
            'data_summary': {},
            'key_metrics': {},
            'insights': []
        }
        
        # Build data summary
        for data_type, df in self.unified_data.items():
            if not df.empty:
                knowledge['data_summary'][data_type] = {
                    'total_records': len(df),
                    'columns': list(df.columns),
                    'date_range': self._get_date_range(df),
                    'key_statistics': self._get_key_statistics(df)
                }
        
        # Build key metrics
        knowledge['key_metrics'] = self.kpi_data
        
        # Generate insights
        knowledge['insights'] = self._generate_insights()
        
        return knowledge
    
    def _get_date_range(self, df):
        """Get date range from dataframe"""
        date_columns = [col for col in df.columns if df[col].dtype == 'datetime64[ns]']
        if not date_columns:
            return None
        
        all_dates = pd.concat([df[col].dropna() for col in date_columns])
        if len(all_dates) == 0:
            return None
        
        return {
            'start': all_dates.min().strftime('%Y-%m-%d'),
            'end': all_dates.max().strftime('%Y-%m-%d'),
            'days': (all_dates.max() - all_dates.min()).days
        }
    
    def _get_key_statistics(self, df):
        """Get key statistics from dataframe"""
        stats = {}
        
        # Status distribution
        status_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status'])]
        if status_cols:
            status_dist = df[status_cols[0]].value_counts().to_dict()
            stats['status_distribution'] = status_dist
        
        # Department distribution
        dept_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department'])]
        if dept_cols:
            dept_dist = df[dept_cols[0]].value_counts().head(5).to_dict()
            stats['top_departments'] = dept_dist
        
        return stats
    
    def _generate_insights(self):
        """Generate automatic insights from data"""
        insights = []
        
        # Total records insight
        total_records = sum([len(df) for df in self.unified_data.values() if not df.empty])
        insights.append(f"ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ø¥Ø¬Ù…Ø§Ù„ÙŠ {total_records:,} Ø³Ø¬Ù„ Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        
        # Compliance insight
        total_open = 0
        total_closed = 0
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_counts = df[col].value_counts()
                    for status, count in status_counts.items():
                        if 'Ù…ÙØªÙˆØ­' in str(status):
                            total_open += count
                        elif 'Ù…ØºÙ„Ù‚' in str(status):
                            total_closed += count
        
        if total_open + total_closed > 0:
            compliance_rate = (total_closed / (total_open + total_closed)) * 100
            insights.append(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‡Ùˆ {compliance_rate:.1f}% ({total_closed:,} Ù…ØºÙ„Ù‚ Ù…Ù† Ø£ØµÙ„ {total_open + total_closed:,})")
        
        # Department insight
        dept_performance = {}
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            dept_col = None
            status_col = None
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                    dept_col = col
                elif any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_col = col
            
            if dept_col and status_col:
                dept_counts = df[dept_col].value_counts()
                top_dept = dept_counts.index[0] if len(dept_counts) > 0 else None
                if top_dept:
                    insights.append(f"Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹ Ù‡Ùˆ {top_dept} Ø¨Ù€ {dept_counts.iloc[0]:,} Ø³Ø¬Ù„")
                    break
        
        return insights
    
    def process_query(self, user_query):
        """Process user query and generate response"""
        user_query = user_query.strip()
        
        # Add to conversation history
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'user_query': user_query,
            'response': None
        })
        
        # Determine query type
        query_type = self._classify_query(user_query)
        
        # Generate response based on query type
        response = self._generate_response(query_type, user_query)
        
        # Update conversation history
        self.conversation_history[-1]['response'] = response
        
        return response
    
    def _classify_query(self, query):
        """Classify user query into categories"""
        query_lower = query.lower()
        
        for category, patterns in self.query_patterns.items():
            for pattern in patterns:
                if pattern.lower() in query_lower:
                    return category
        
        # Default classification based on keywords
        if any(word in query_lower for word in ['ÙƒÙ…', 'Ø¹Ø¯Ø¯', 'Ø¥Ø¬Ù…Ø§Ù„ÙŠ', 'how many', 'total']):
            return 'statistics'
        elif any(word in query_lower for word in ['Ø£ÙØ¶Ù„', 'Ø£Ø³ÙˆØ£', 'best', 'worst']):
            return 'department_performance'
        elif any(word in query_lower for word in ['Ù…ØªÙ‰', 'when', 'ØªØ§Ø±ÙŠØ®', 'date']):
            return 'trends'
        else:
            return 'general'
    
    def _generate_response(self, query_type, user_query):
        """Generate response based on query type"""
        try:
            if query_type == 'total_incidents':
                return self._get_incidents_summary()
            elif query_type == 'open_cases':
                return self._get_open_cases_summary()
            elif query_type == 'closed_cases':
                return self._get_closed_cases_summary()
            elif query_type == 'department_performance':
                return self._get_department_performance()
            elif query_type == 'risk_assessment':
                return self._get_risk_assessment_summary()
            elif query_type == 'compliance_rate':
                return self._get_compliance_summary()
            elif query_type == 'trends':
                return self._get_trends_summary()
            elif query_type == 'statistics':
                return self._get_general_statistics()
            else:
                return self._get_general_response(user_query)
        except Exception as e:
            return {
                'text': f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ: {str(e)}",
                'chart': None,
                'data': None
            }
    
    def _get_incidents_summary(self):
        """Get incidents summary"""
        if 'incidents' not in self.unified_data or self.unified_data['incidents'].empty:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø­ÙˆØ§Ø¯Ø« Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        incidents_df = self.unified_data['incidents']
        total_incidents = len(incidents_df)
        
        # Get status distribution
        status_dist = {}
        for col in incidents_df.columns:
            if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                status_dist = incidents_df[col].value_counts().to_dict()
                break
        
        # Create chart
        if status_dist:
            chart_data = pd.DataFrame([
                {'Ø§Ù„Ø­Ø§Ù„Ø©': status, 'Ø§Ù„Ø¹Ø¯Ø¯': count}
                for status, count in status_dist.items()
            ])
            
            fig = px.pie(
                chart_data,
                values='Ø§Ù„Ø¹Ø¯Ø¯',
                names='Ø§Ù„Ø­Ø§Ù„Ø©',
                title="ØªÙˆØ²ÙŠØ¹ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø«"
            )
        else:
            fig = None
        
        text = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ù…Ø³Ø¬Ù„Ø©: {total_incidents:,} Ø­Ø§Ø¯Ø«\n"
        if status_dist:
            text += "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª:\n"
            for status, count in status_dist.items():
                text += f"â€¢ {status}: {count:,} Ø­Ø§Ø¯Ø«\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': incidents_df.head(10)
        }
    
    def _get_open_cases_summary(self):
        """Get open cases summary"""
        open_cases = {}
        total_open = 0
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    open_count = len(df[df[col].str.contains('Ù…ÙØªÙˆØ­', na=False)])
                    if open_count > 0:
                        open_cases[data_type] = open_count
                        total_open += open_count
                    break
        
        if not open_cases:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø§Ù„Ø§Øª Ù…ÙØªÙˆØ­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': data_type, 'Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©': count}
            for data_type, count in open_cases.items()
        ])
        
        fig = px.bar(
            chart_data,
            x='Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            y='Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©',
            title="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
        )
        
        text = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {total_open:,}\n"
        text += "Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
        for data_type, count in open_cases.items():
            text += f"â€¢ {data_type}: {count:,} Ø­Ø§Ù„Ø© Ù…ÙØªÙˆØ­Ø©\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': chart_data
        }
    
    def _get_closed_cases_summary(self):
        """Get closed cases summary"""
        closed_cases = {}
        total_closed = 0
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    closed_count = len(df[df[col].str.contains('Ù…ØºÙ„Ù‚', na=False)])
                    if closed_count > 0:
                        closed_cases[data_type] = closed_count
                        total_closed += closed_count
                    break
        
        if not closed_cases:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø§Ù„Ø§Øª Ù…ØºÙ„Ù‚Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': data_type, 'Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©': count}
            for data_type, count in closed_cases.items()
        ])
        
        fig = px.bar(
            chart_data,
            x='Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            y='Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©',
            title="Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            color_discrete_sequence=['#2ca02c']
        )
        
        text = f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {total_closed:,}\n"
        text += "Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
        for data_type, count in closed_cases.items():
            text += f"â€¢ {data_type}: {count:,} Ø­Ø§Ù„Ø© Ù…ØºÙ„Ù‚Ø©\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': chart_data
        }
    
    def _get_department_performance(self):
        """Get department performance analysis"""
        dept_performance = {}
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            dept_col = None
            status_col = None
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                    dept_col = col
                elif any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_col = col
            
            if dept_col and status_col:
                dept_status = df.groupby(dept_col)[status_col].value_counts().unstack(fill_value=0)
                for dept in dept_status.index:
                    closed = dept_status.loc[dept].get('Ù…ØºÙ„Ù‚', 0)
                    total = dept_status.loc[dept].sum()
                    compliance_rate = (closed / total * 100) if total > 0 else 0
                    
                    if dept not in dept_performance:
                        dept_performance[dept] = {'total': 0, 'closed': 0, 'rates': []}
                    
                    dept_performance[dept]['total'] += total
                    dept_performance[dept]['closed'] += closed
                    dept_performance[dept]['rates'].append(compliance_rate)
        
        if not dept_performance:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ù…ØªØ§Ø­Ø©.",
                'chart': None,
                'data': None
            }
        
        # Calculate average performance
        performance_data = []
        for dept, data in dept_performance.items():
            avg_rate = np.mean(data['rates']) if data['rates'] else 0
            performance_data.append({
                'Ø§Ù„Ù‚Ø·Ø§Ø¹': dept,
                'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„': avg_rate,
                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª': data['total'],
                'Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©': data['closed']
            })
        
        performance_df = pd.DataFrame(performance_data)
        performance_df = performance_df.sort_values('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„', ascending=False)
        
        # Create chart
        fig = px.bar(
            performance_df.head(10),
            x='Ø§Ù„Ù‚Ø·Ø§Ø¹',
            y='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            title="Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª - Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„",
            color='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            color_continuous_scale='RdYlGn'
        )
        fig.update_layout(xaxis_tickangle=-45)
        
        # Generate text summary
        best_dept = performance_df.iloc[0]
        worst_dept = performance_df.iloc[-1]
        
        text = f"ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª:\n\n"
        text += f"Ø£ÙØ¶Ù„ Ù‚Ø·Ø§Ø¹: {best_dept['Ø§Ù„Ù‚Ø·Ø§Ø¹']} Ø¨Ù…Ø¹Ø¯Ù„ Ø§Ù…ØªØ«Ø§Ù„ {best_dept['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„']:.1f}%\n"
        text += f"Ø£Ø¶Ø¹Ù Ù‚Ø·Ø§Ø¹: {worst_dept['Ø§Ù„Ù‚Ø·Ø§Ø¹']} Ø¨Ù…Ø¹Ø¯Ù„ Ø§Ù…ØªØ«Ø§Ù„ {worst_dept['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„']:.1f}%\n\n"
        text += f"Ù…ØªÙˆØ³Ø· Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¹Ø§Ù…: {performance_df['Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„'].mean():.1f}%"
        
        return {
            'text': text,
            'chart': fig,
            'data': performance_df
        }
    
    def _get_risk_assessment_summary(self):
        """Get risk assessment summary"""
        if 'risk_assessments' not in self.unified_data or self.unified_data['risk_assessments'].empty:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø­Ø§Ù„ÙŠØ§Ù‹.",
                'chart': None,
                'data': None
            }
        
        risk_df = self.unified_data['risk_assessments']
        total_assessments = len(risk_df)
        
        # Get risk level distribution
        risk_levels = {'Ø¹Ø§Ù„ÙŠ': 0, 'Ù…ØªÙˆØ³Ø·': 0, 'Ù…Ù†Ø®ÙØ¶': 0}
        
        for col in risk_df.columns:
            if any(keyword in col.lower() for keyword in ['ØªØµÙ†ÙŠÙ', 'Ù…Ø®Ø§Ø·Ø±', 'risk']):
                level_counts = risk_df[col].value_counts()
                for level, count in level_counts.items():
                    level_str = str(level).lower()
                    if 'Ø¹Ø§Ù„ÙŠ' in level_str or 'high' in level_str:
                        risk_levels['Ø¹Ø§Ù„ÙŠ'] += count
                    elif 'Ù…ØªÙˆØ³Ø·' in level_str or 'medium' in level_str:
                        risk_levels['Ù…ØªÙˆØ³Ø·'] += count
                    elif 'Ù…Ù†Ø®ÙØ¶' in level_str or 'low' in level_str:
                        risk_levels['Ù…Ù†Ø®ÙØ¶'] += count
                break
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±': level, 'Ø§Ù„Ø¹Ø¯Ø¯': count}
            for level, count in risk_levels.items() if count > 0
        ])
        
        if not chart_data.empty:
            fig = px.pie(
                chart_data,
                values='Ø§Ù„Ø¹Ø¯Ø¯',
                names='Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±',
                title="ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±",
                color_discrete_map={
                    'Ø¹Ø§Ù„ÙŠ': '#d62728',
                    'Ù…ØªÙˆØ³Ø·': '#ff7f0e',
                    'Ù…Ù†Ø®ÙØ¶': '#2ca02c'
                }
            )
        else:
            fig = None
        
        text = f"Ù…Ù„Ø®Øµ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n\n"
        text += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª: {total_assessments:,}\n"
        if any(risk_levels.values()):
            text += "ØªÙˆØ²ÙŠØ¹ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±:\n"
            for level, count in risk_levels.items():
                if count > 0:
                    percentage = (count / sum(risk_levels.values())) * 100
                    text += f"â€¢ {level}: {count:,} ({percentage:.1f}%)\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': risk_df.head(10)
        }
    
    def _get_compliance_summary(self):
        """Get overall compliance summary"""
        total_open = 0
        total_closed = 0
        compliance_by_type = {}
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            type_open = 0
            type_closed = 0
            
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_counts = df[col].value_counts()
                    for status, count in status_counts.items():
                        if 'Ù…ÙØªÙˆØ­' in str(status):
                            type_open += count
                            total_open += count
                        elif 'Ù…ØºÙ„Ù‚' in str(status):
                            type_closed += count
                            total_closed += count
                    break
            
            if type_open + type_closed > 0:
                compliance_rate = (type_closed / (type_open + type_closed)) * 100
                compliance_by_type[data_type] = {
                    'rate': compliance_rate,
                    'closed': type_closed,
                    'total': type_open + type_closed
                }
        
        if total_open + total_closed == 0:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„.",
                'chart': None,
                'data': None
            }
        
        overall_compliance = (total_closed / (total_open + total_closed)) * 100
        
        # Create chart
        chart_data = pd.DataFrame([
            {'Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª': data_type, 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„': data['rate']}
            for data_type, data in compliance_by_type.items()
        ])
        
        fig = px.bar(
            chart_data,
            x='Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª',
            y='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            title="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            color='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„',
            color_continuous_scale='RdYlGn'
        )
        fig.update_layout(xaxis_tickangle=-45)
        
        text = f"Ù…Ù„Ø®Øµ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¹Ø§Ù…:\n\n"
        text += f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {overall_compliance:.1f}%\n"
        text += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª: {total_open + total_closed:,}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {total_closed:,}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {total_open:,}\n\n"
        text += "Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n"
        
        for data_type, data in compliance_by_type.items():
            text += f"â€¢ {data_type}: {data['rate']:.1f}% ({data['closed']}/{data['total']})\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': chart_data
        }
    
    def _get_trends_summary(self):
        """Get trends analysis"""
        trends_data = {}
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            date_col = None
            for col in df.columns:
                if df[col].dtype == 'datetime64[ns]':
                    date_col = col
                    break
            
            if date_col:
                monthly_trend = df.groupby(pd.Grouper(key=date_col, freq='M')).size()
                if len(monthly_trend) > 1:
                    trends_data[data_type] = monthly_trend
        
        if not trends_data:
            return {
                'text': "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©.",
                'chart': None,
                'data': None
            }
        
        # Create combined trends chart
        fig = go.Figure()
        
        for data_type, trend in trends_data.items():
            fig.add_trace(go.Scatter(
                x=trend.index,
                y=trend.values,
                mode='lines+markers',
                name=data_type,
                line=dict(width=2)
            ))
        
        fig.update_layout(
            title="Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            xaxis_title="Ø§Ù„ØªØ§Ø±ÙŠØ®",
            yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª",
            hovermode='x unified'
        )
        
        text = "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©:\n\n"
        
        for data_type, trend in trends_data.items():
            latest_value = trend.iloc[-1]
            previous_value = trend.iloc[-2] if len(trend) > 1 else latest_value
            change = ((latest_value - previous_value) / previous_value * 100) if previous_value != 0 else 0
            
            text += f"â€¢ {data_type}:\n"
            text += f"  - Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {latest_value:,}\n"
            text += f"  - Ø§Ù„ØªØºÙŠÙŠØ±: {change:+.1f}% Ù…Ù† Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚\n\n"
        
        return {
            'text': text,
            'chart': fig,
            'data': None
        }
    
    def _get_general_statistics(self):
        """Get general statistics"""
        stats = {
            'total_records': 0,
            'data_types': len(self.unified_data),
            'date_ranges': {},
            'top_departments': {},
            'status_summary': {'Ù…ÙØªÙˆØ­': 0, 'Ù…ØºÙ„Ù‚': 0}
        }
        
        for data_type, df in self.unified_data.items():
            if df.empty:
                continue
            
            stats['total_records'] += len(df)
            
            # Get date range
            date_range = self._get_date_range(df)
            if date_range:
                stats['date_ranges'][data_type] = date_range
            
            # Get department info
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø¥Ø¯Ø§Ø±Ø©', 'Ù‚Ø·Ø§Ø¹', 'department']):
                    dept_counts = df[col].value_counts().head(3)
                    stats['top_departments'][data_type] = dept_counts.to_dict()
                    break
            
            # Get status info
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['Ø­Ø§Ù„Ø©', 'status']):
                    status_counts = df[col].value_counts()
                    for status, count in status_counts.items():
                        if 'Ù…ÙØªÙˆØ­' in str(status):
                            stats['status_summary']['Ù…ÙØªÙˆØ­'] += count
                        elif 'Ù…ØºÙ„Ù‚' in str(status):
                            stats['status_summary']['Ù…ØºÙ„Ù‚'] += count
                    break
        
        text = f"Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù†Ø¸Ø§Ù…:\n\n"
        text += f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {stats['total_records']:,}\n"
        text += f"Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {stats['data_types']}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {stats['status_summary']['Ù…ÙØªÙˆØ­']:,}\n"
        text += f"Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: {stats['status_summary']['Ù…ØºÙ„Ù‚']:,}\n\n"
        
        if stats['date_ranges']:
            text += "Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©:\n"
            for data_type, date_range in stats['date_ranges'].items():
                text += f"â€¢ {data_type}: Ù…Ù† {date_range['start']} Ø¥Ù„Ù‰ {date_range['end']} ({date_range['days']} ÙŠÙˆÙ…)\n"
        
        return {
            'text': text,
            'chart': None,
            'data': None
        }
    
    def _get_general_response(self, user_query):
        """Get general response for unclassified queries"""
        # Check if query contains specific keywords
        query_lower = user_query.lower()
        
        if any(word in query_lower for word in ['Ù…Ø³Ø§Ø¹Ø¯Ø©', 'help']):
            return {
                'text': """ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù†:

â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
â€¢ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙˆØ§Ù„Ù…ØºÙ„Ù‚Ø©
â€¢ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
â€¢ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±
â€¢ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„
â€¢ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
â€¢ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©

Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:
- "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ù…ÙØªÙˆØ­Ø©ØŸ"
- "Ù…Ø§ Ù‡Ùˆ Ø£Ø¯Ø§Ø¡ Ù‚Ø·Ø§Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ØŸ"
- "Ø£Ø¸Ù‡Ø± Ù„ÙŠ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"
- "Ù…Ø§ Ù‡Ùˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ØŸ"
""",
                'chart': None,
                'data': None
            }
        
        # Provide insights from knowledge base
        insights_text = "Ø¥Ù„ÙŠÙƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø±Ø¤Ù‰ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n\n"
        for insight in self.knowledge_base['insights'][:3]:
            insights_text += f"â€¢ {insight}\n"
        
        insights_text += "\nÙŠÙ…ÙƒÙ†Ùƒ Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ø§Ù‹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„."
        
        return {
            'text': insights_text,
            'chart': None,
            'data': None
        }
    
    def get_conversation_history(self):
        """Get conversation history"""
        return self.conversation_history
    
    def clear_conversation(self):
        """Clear conversation history"""
        self.conversation_history = []
    
    def export_conversation(self):
        """Export conversation history"""
        if not self.conversation_history:
            return None
        
        conversation_data = []
        for entry in self.conversation_history:
            conversation_data.append({
                'timestamp': entry['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                'user_query': entry['user_query'],
                'response_text': entry['response']['text'] if entry['response'] else None
            })
        
        return pd.DataFrame(conversation_data)

def create_chatbot_interface(unified_data, kpi_data):
    """Create chatbot interface in Streamlit"""
    st.subheader("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    
    # Initialize chatbot
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = GeminiChatbot(unified_data, kpi_data)
    
    # Chat interface
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message.get("chart"):
                st.plotly_chart(message["chart"], use_container_width=True)
            if message.get("data") is not None:
                st.dataframe(message["data"], use_container_width=True)
    
    # Chat input
    if prompt := st.chat_input("Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø© ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Get bot response
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                response = st.session_state.chatbot.process_query(prompt)
            
            st.markdown(response['text'])
            
            if response['chart']:
                st.plotly_chart(response['chart'], use_container_width=True)
            
            if response['data'] is not None:
                st.dataframe(response['data'], use_container_width=True)
            
            # Add assistant response to chat history
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response['text'],
                "chart": response['chart'],
                "data": response['data']
            })
    
    # Sidebar controls
    with st.sidebar:
        st.subheader("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")
        
        if st.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
            st.session_state.messages = []
            st.session_state.chatbot.clear_conversation()
            st.rerun()
        
        if st.button("ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
            conversation_df = st.session_state.chatbot.export_conversation()
            if conversation_df is not None:
                csv = conversation_df.to_csv(index=False)
                st.download_button(
                    label="ØªØ­Ù…ÙŠÙ„ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
                    data=csv,
                    file_name=f"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø© Ù„ØªØµØ¯ÙŠØ±Ù‡Ø§")
        
        # Quick questions
        st.subheader("Ø£Ø³Ø¦Ù„Ø© Ø³Ø±ÙŠØ¹Ø©")
        quick_questions = [
            "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØŸ",
            "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©ØŸ",
            "Ø£Ø¸Ù‡Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª",
            "Ù…Ø§ Ù‡Ùˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ØŸ",
            "Ø£Ø¸Ù‡Ø± Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©"
        ]
        
        for question in quick_questions:
            if st.button(question, key=f"quick_{question}"):
                # Simulate clicking the question
                st.session_state.messages.append({"role": "user", "content": question})
                
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                    response = st.session_state.chatbot.process_query(question)
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response['text'],
                    "chart": response['chart'],
                    "data": response['data']
                })
                st.rerun()